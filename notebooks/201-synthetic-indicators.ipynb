{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "This notebook generates synthetic indicator data for testing and prototyping purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rioxarray  # noqa: F401\n",
    "import xarray as xr\n",
    "\n",
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SITE_ID = \"degero\"\n",
    "EXTENT_ID = \"extent-1\"\n",
    "PATH_OUT = os.path.join(\"synthetic-indicators\", f\"{SITE_ID}-{EXTENT_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath(PATH_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(PATH_OUT):\n",
    "    shutil.rmtree(PATH_OUT)\n",
    "os.makedirs(PATH_OUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "info.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(PATH_OUT, \"info.json\")\n",
    "with open(filename, \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"name\": \"synthetic indicator extent-1\",\n",
    "            \"description\": \"This is a synthetic indicator for testing purposes.\",\n",
    "            \"site_id\": SITE_ID,\n",
    "            \"default_variable_loading_name\": \"loading_001\",\n",
    "        },\n",
    "        f,\n",
    "        indent=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "peat_extent.tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_min = 19.4342728416868\n",
    "lat_min = 64.0867100842452\n",
    "lon_max = 19.702569859525383\n",
    "lat_max = 64.2372650939366"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(PATH_OUT, \"peat_extent.tiff\")\n",
    "\n",
    "# Grid size\n",
    "n_x, n_y = 100, 100\n",
    "\n",
    "array = np.random.choice([0, 1], size=(n_y, n_x), p=[0.8, 0.2])\n",
    "x = np.linspace(lon_min, lon_max, n_x)\n",
    "y = np.linspace(lat_min, lat_max, n_y)\n",
    "ds = xr.DataArray(\n",
    "    array,\n",
    "    coords={\"y\": y, \"x\": x},\n",
    "    dims=(\"y\", \"x\"),\n",
    "    name=\"peat_extent\",\n",
    ")\n",
    "ds.name = \"peat_extent\"\n",
    "ds.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "\n",
    "ds.rio.to_raster(filename, dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "time_series.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_index = pd.date_range(start=\"2015-01-01\", end=\"2019-12-31\", freq=\"D\")\n",
    "n_vars = 5\n",
    "columns = [f\"variable_{i + 1}\" for i in range(n_vars)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(len(date_index))\n",
    "data_df = pd.DataFrame(index=date_index)\n",
    "\n",
    "for i, col in enumerate(columns):\n",
    "    \"\"\"\n",
    "    Generate synthetic data for each variable with:\n",
    "\n",
    "    - Random mean and standard deviation for noise\n",
    "    - Linear trend with random slope\n",
    "    - Seasonal pattern with random amplitude and phase\n",
    "    \"\"\"\n",
    "    mean = np.random.uniform(-2, 2)\n",
    "    std = np.random.uniform(0.1, 0.4)\n",
    "    slope = np.random.uniform(-0.01, 0.01)\n",
    "    phase = np.random.uniform(0, 2 * np.pi)\n",
    "    amplitude = np.random.uniform(0.5, 2)\n",
    "\n",
    "    noise = np.random.normal(loc=mean, scale=std, size=len(date_index))\n",
    "    trend = slope * time\n",
    "    season = amplitude * np.sin(2 * np.pi * time / 365 + phase)\n",
    "\n",
    "    data_df[col] = noise + trend + season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all variables as overlayed curves\n",
    "curves = [hv.Curve((data_df.index, data_df[col]), label=col) for col in data_df.columns]\n",
    "df_hv = hv.Overlay(curves)\n",
    "df_hv.opts(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    legend_position=\"right\",\n",
    "    xlabel=\"Date\",\n",
    "    ylabel=\"Value\",\n",
    "    title=\"Synthetic Indicators\",\n",
    "    show_grid=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_df = pd.DataFrame(index=date_index)\n",
    "\n",
    "for col in columns:\n",
    "    \"\"\"\n",
    "    Generate synthetic variance data for each variable with:\n",
    "\n",
    "    - Base variance with random value\n",
    "    - noise\n",
    "    - Seasonal variance with a sinusoidal pattern\n",
    "    \"\"\"\n",
    "\n",
    "    base_variance = np.random.uniform(0.5, 3.0)\n",
    "    noise = np.random.normal(0, 0.1, len(date_index))\n",
    "    seasonal_variance = 0.2 * np.sin(2 * np.pi * time / 365 + np.random.uniform(0, 2 * np.pi))\n",
    "\n",
    "    variance_df[col] = base_variance + seasonal_variance + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all variables as overlayed curves\n",
    "curves = [hv.Curve((variance_df.index, variance_df[col]), label=col) for col in variance_df.columns]\n",
    "df_hv = hv.Overlay(curves)\n",
    "df_hv.opts(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    legend_position=\"right\",\n",
    "    xlabel=\"Date\",\n",
    "    ylabel=\"Value\",\n",
    "    title=\"Synthetic Indicators - variance\",\n",
    "    show_grid=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(PATH_OUT, \"time_series.h5\")\n",
    "data_df.to_hdf(filename, key=\"data\")\n",
    "variance_df.to_hdf(filename, key=\"variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "variable_loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_loading = os.path.join(PATH_OUT, \"variable_loading\")\n",
    "os.makedirs(variable_loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(variable_loading, \"loading_001.json\")\n",
    "with open(filename, \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"name\": \"loading_001\",\n",
    "            \"description\": \"This is a synthetic variable loading for testing purposes.\",\n",
    "            \"optimal_values\": {\n",
    "                \"variable_1\": 0.5,\n",
    "            },\n",
    "            \"variable_loadings\": {\n",
    "                \"variable_1\": 0.1,\n",
    "                \"variable_2\": 0.2,\n",
    "                \"variable_3\": 0.3,\n",
    "                \"variable_4\": 0.4,\n",
    "                \"variable_5\": 0.5,\n",
    "            },\n",
    "        },\n",
    "        f,\n",
    "        indent=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(variable_loading, \"loading_002.json\")\n",
    "with open(filename, \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"name\": \"loading_002\",\n",
    "            \"description\": \"This is a synthetic variable loading for testing purposes.\",\n",
    "            \"optimal_values\": {\n",
    "                \"variable_2\": 0.1,\n",
    "            },\n",
    "            \"variable_loadings\": {\n",
    "                \"variable_1\": 0.1,\n",
    "                \"variable_2\": -0.2,\n",
    "                \"variable_3\": 0.3,\n",
    "                \"variable_4\": -0.4,\n",
    "                \"variable_5\": 0.5,\n",
    "            },\n",
    "        },\n",
    "        f,\n",
    "        indent=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "! tree {PATH_OUT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wpl-notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
